{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf14d57-ac2c-4ecd-a200-e4d907c29333",
   "metadata": {},
   "source": [
    "# HPC intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af640881-f322-4287-a6f4-ef65e0ee91cf",
   "metadata": {},
   "source": [
    "## atools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac4663-1aa8-4c0c-8490-0df632a54d72",
   "metadata": {},
   "source": [
    "There are many situations in which you want to run an application for (potentially many) different input parameters.  These parameters can be command line options you run your application with, or file names you provide and so on.\n",
    "\n",
    "Of course, you could submit a job for each of the instances of your problem, but that would result in many jobs.  Moreover, quite some bookkeeping would be required if some instances fail, while others succeed.  You typically don't have a convenient way to get an overview of which instances failed, and hence have to be redone.\n",
    "\n",
    "Alternatively, you could simply do all these instances looping over all the parameters.  This would result in potentially prohibitively long run times, and, more importantly, you would not be exploiting a supercomputers main feature: executing work in parallel.\n",
    "\n",
    "atools has been designed to make it easy for you to run many instances of a problem in parallel, and it takes care of the bookkeeping for you as well.  An instance of the problem that you want to compute is called a *work item* in the context of atools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3be777-a69b-47f8-a329-facbec0330f2",
   "metadata": {},
   "source": [
    "### Job script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de7a44-8062-4bbb-bf8e-e2362f27ba17",
   "metadata": {},
   "source": [
    "The first step is to make a few modifications to your job script.  By way of example, use a script that simply calculates and displays the product of two numbers that you also used in the [tutorial on jobs](020_jobs.ipynb).\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env -S bash -l\n",
    "#SBATCH --account=lp_tutorial\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:05:00\n",
    "\n",
    "# actual computation, a bit boring\n",
    "for i in $(seq 1 10)\n",
    "do\n",
    "    for j in $(seq 1 10)\n",
    "    do\n",
    "        echo $(( $i * $j ))\n",
    "    done\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8376c-c321-4c94-b67e-a633203f8a49",
   "metadata": {},
   "source": [
    "In this job script, you do all computations sequentially, but to speed things up, you would like to do them in parallel as independent jobs.  So you can rewrite the job script such that it only does a single multiplication.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env -S bash -l\n",
    "#SBATCH --account=lp_multiscale_physics\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:05:00\n",
    "\n",
    "# actual computation, a bit boring\n",
    "echo $(( $i * $j ))\n",
    "```\n",
    "\n",
    "The job script has been adapted to compute a single work item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2603b-1b9c-41cd-8e04-55ce27482b50",
   "metadata": {},
   "source": [
    "This is where atools comes in.  You can make a few more modifications to this job script to use it.  The values of `i` and `j` will be read from a Comma Separated Value file (CSV file).\n",
    "\n",
    "The first line of this file lists the names of the variables, each line after that the values that correspond to the work items.  So for this example, that would look as follows.  \n",
    "\n",
    "```\n",
    "i,j\n",
    "1,1\n",
    "1,2\n",
    "1,3\n",
    "...\n",
    "10,8\n",
    "10,9\n",
    "10,10\n",
    "```\n",
    "\n",
    "You don't have to type all that, there is a data file `data.csv` available that you can copy.  You can find it in the `021_artefacts` directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d44421c-e833-455a-bf02-e810952a235c",
   "metadata": {},
   "source": [
    "As it is, this script would fail since at this point the variables `i` and `j` are not defined.  You have to make sure that atools can do its magic.  For that purpose, you have to make a few more modifications to the job script.\n",
    "\n",
    "1. Load the `atools` module.\n",
    "2. Log the start of the work item.\n",
    "3. Make sure that the variables used in the script are initialized.\n",
    "4. Log the end of the work item.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env -S bash -l\n",
    "#SBATCH --account=lp_tutorial\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:05:00\n",
    "\n",
    "# make sure the module system starts from a clean slate and load the atools module\n",
    "module purge\n",
    "module load atools\n",
    "\n",
    "# log the start of the work item\n",
    "alog  --state start\n",
    "\n",
    "# initialize the variables\n",
    "source <(aenv --data data.csv)\n",
    "\n",
    "# actual computation, a bit boring\n",
    "echo $(( $i * $j ))\n",
    "\n",
    "# log the end of the work item\n",
    "alog  --state end  --exit $?\n",
    "```\n",
    "\n",
    "Now your job script is fully adapted to use atools features.  It is available in the `021_artefacts` directory as `jobscript_parallel.slurm`.   Don't forget to change the credit account name to the one you have access to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ca124-5140-4576-81b9-a336dfba0fff",
   "metadata": {},
   "source": [
    "### Job submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2da63-b165-495b-bf6b-bced8c02a8c3",
   "metadata": {},
   "source": [
    "You can submit an atools job almost the same way as an ordinary job, except that you need to specify the `--array` option for `sbatch`.  If you know the number of work items, 100 in the `data.csv` file you are using, you can simply use `--array=1-100`.  Otherwise, atools can help you determine it easily.\n",
    "\n",
    "First, load the atools module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a85580-e2cb-4096-bfab-44b9fd78517b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module load atools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c14a9-e49b-4459-b26d-dafb0a6da0d0",
   "metadata": {},
   "source": [
    "Next, submit the job as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79bed48-009f-4ff6-a64e-e1ee7f864555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 60666714 on cluster wice\n"
     ]
    }
   ],
   "source": [
    "sbatch  --cluster=wice  --array=$(arange --data data.csv)  jobscript_parallel.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6c0d0-043d-47b7-a29f-13afa9dad826",
   "metadata": {},
   "source": [
    "When you check the queue, you will notice that\n",
    "* when your job is not running yet, the job ID is somewhat unusual, `_[1-100]` is appended to it;\n",
    "* when your job has started to run, you will see many entries where a single number was appended to the job ID; these are the indivitual work items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6cd489-11cb-41a9-a62d-64f5309b808d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: wice\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "  60666714_[1-100]     batch jobscrip vsc30032 PD       0:00      1 (Priority)\n",
      "          60666711 interacti sys/dash vsc30032  R       2:53      1 k28i14\n"
     ]
    }
   ],
   "source": [
    "squeue --cluster=wice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f10981-94aa-48af-ae2f-57768b3149e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: wice\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "  60666714_[1-100]     batch jobscrip vsc30032 PD       0:00      1 (Priority)\n",
      "          60666711 interacti sys/dash vsc30032  R       3:02      1 k28i14\n"
     ]
    }
   ],
   "source": [
    "squeue --cluster=wice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2a29d3-bfa5-4a5d-aa16-1271629e6207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: wice\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      " 60666714_[21-100]     batch jobscrip vsc30032 PD       0:00      1 (Priority)\n",
      "        60666714_3     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "        60666714_4     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "        60666714_5     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "        60666714_6     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "        60666714_8     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "        60666714_9     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_10     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_11     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_12     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_13     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_14     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_15     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_16     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_19     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "       60666714_20     batch jobscrip vsc30032  R       0:19      1 s28c11n2\n",
      "          60666711 interacti sys/dash vsc30032  R       3:26      1 k28i14\n"
     ]
    }
   ],
   "source": [
    "squeue --cluster=wice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045d6c53-482b-4781-bcec-f3646293dc34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: wice\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      " 60666714_[21-100]     batch jobscrip vsc30032 PD       0:00      1 (Priority)\n",
      "       60666714_10     batch jobscrip vsc30032  R       0:39      1 s28c11n2\n",
      "          60666711 interacti sys/dash vsc30032  R       3:46      1 k28i14\n"
     ]
    }
   ],
   "source": [
    "squeue --cluster=wice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e778bd56-4c76-4144-994a-004ee5329d24",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER: wice\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          60666711 interacti sys/dash vsc30032  R      11:19      1 k28i14\n"
     ]
    }
   ],
   "source": [
    "squeue --cluster=wice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508b7b2-561b-4743-8a37-75d6bdcb0bfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "When the job finishes, you will notice a lot of files, each containing the output of a single work item.  You should have as many as there are work items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d641b1-c36d-4c34-befd-8070775670f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm-60666714_100.out\tslurm-60666714_40.out  slurm-60666714_71.out\n",
      "slurm-60666714_10.out\tslurm-60666714_41.out  slurm-60666714_72.out\n",
      "slurm-60666714_11.out\tslurm-60666714_42.out  slurm-60666714_73.out\n",
      "slurm-60666714_12.out\tslurm-60666714_43.out  slurm-60666714_74.out\n",
      "slurm-60666714_13.out\tslurm-60666714_44.out  slurm-60666714_75.out\n",
      "slurm-60666714_14.out\tslurm-60666714_45.out  slurm-60666714_76.out\n",
      "slurm-60666714_15.out\tslurm-60666714_46.out  slurm-60666714_77.out\n",
      "slurm-60666714_16.out\tslurm-60666714_47.out  slurm-60666714_78.out\n",
      "slurm-60666714_17.out\tslurm-60666714_48.out  slurm-60666714_79.out\n",
      "slurm-60666714_18.out\tslurm-60666714_49.out  slurm-60666714_7.out\n",
      "slurm-60666714_19.out\tslurm-60666714_4.out   slurm-60666714_80.out\n",
      "slurm-60666714_1.out\tslurm-60666714_50.out  slurm-60666714_81.out\n",
      "slurm-60666714_20.out\tslurm-60666714_51.out  slurm-60666714_82.out\n",
      "slurm-60666714_21.out\tslurm-60666714_52.out  slurm-60666714_83.out\n",
      "slurm-60666714_22.out\tslurm-60666714_53.out  slurm-60666714_84.out\n",
      "slurm-60666714_23.out\tslurm-60666714_54.out  slurm-60666714_85.out\n",
      "slurm-60666714_24.out\tslurm-60666714_55.out  slurm-60666714_86.out\n",
      "slurm-60666714_25.out\tslurm-60666714_56.out  slurm-60666714_87.out\n",
      "slurm-60666714_26.out\tslurm-60666714_57.out  slurm-60666714_88.out\n",
      "slurm-60666714_27.out\tslurm-60666714_58.out  slurm-60666714_89.out\n",
      "slurm-60666714_28.out\tslurm-60666714_59.out  slurm-60666714_8.out\n",
      "slurm-60666714_29.out\tslurm-60666714_5.out   slurm-60666714_90.out\n",
      "slurm-60666714_2.out\tslurm-60666714_60.out  slurm-60666714_91.out\n",
      "slurm-60666714_30.out\tslurm-60666714_61.out  slurm-60666714_92.out\n",
      "slurm-60666714_31.out\tslurm-60666714_62.out  slurm-60666714_93.out\n",
      "slurm-60666714_32.out\tslurm-60666714_63.out  slurm-60666714_94.out\n",
      "slurm-60666714_33.out\tslurm-60666714_64.out  slurm-60666714_95.out\n",
      "slurm-60666714_34.out\tslurm-60666714_65.out  slurm-60666714_96.out\n",
      "slurm-60666714_35.out\tslurm-60666714_66.out  slurm-60666714_97.out\n",
      "slurm-60666714_36.out\tslurm-60666714_67.out  slurm-60666714_98.out\n",
      "slurm-60666714_37.out\tslurm-60666714_68.out  slurm-60666714_99.out\n",
      "slurm-60666714_38.out\tslurm-60666714_69.out  slurm-60666714_9.out\n",
      "slurm-60666714_39.out\tslurm-60666714_6.out\n",
      "slurm-60666714_3.out\tslurm-60666714_70.out\n"
     ]
    }
   ],
   "source": [
    "ls slurm-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f7af600-11f4-4bf1-a036-0cc1d5467e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "ls slurm-*.out | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72eba3b9-7d6a-4bf8-88be-8a9214a99f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM_JOB_ID: 60666714\n",
      "SLURM_JOB_USER: vsc30032\n",
      "SLURM_JOB_ACCOUNT: lpt2_sysadmin\n",
      "SLURM_JOB_NAME: jobscript_parallel.slurm\n",
      "SLURM_CLUSTER_NAME: wice\n",
      "SLURM_JOB_PARTITION: batch\n",
      "SLURM_ARRAY_JOB_ID: 60666714\n",
      "SLURM_ARRAY_TASK_ID: 100\n",
      "SLURM_NNODES: 1\n",
      "SLURM_NODELIST: m28c20n2\n",
      "SLURM_JOB_CPUS_PER_NODE: 1\n",
      "Date: Thu Aug 31 16:57:23 CEST 2023\n",
      "Walltime: 00-00:05:00\n",
      "========================================================================\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "cat slurm-*_100.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104815-1d86-42c6-b071-d62f4754449c",
   "metadata": {},
   "source": [
    "Indeed, work item 100 would be the multiplication of the values 10 and 10.  It is the last line in `data.csv` and hence your last work item.\n",
    "\n",
    "Since this is just a tutorial job, you probably would like to remove these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4b1755-db84-439f-819a-7312a8edbaba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm slurm-*.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27760f7e-47a2-4bd4-8edf-d771051da1f7",
   "metadata": {},
   "source": [
    "### Log file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8c321-6d56-4532-92fd-7da90ed1d2e9",
   "metadata": {},
   "source": [
    "You will remember that you enabled logging using the `alog` commands in `jobscript_parallel.slurm`.  This has resulted in a file that contains information about the work items' execution:\n",
    "\n",
    "  1. its number\n",
    "  1. when they started,\n",
    "  1. the name of the compute node the work item was executed on,\n",
    "  1. when they completed, and\n",
    "  1. the exit status, if there was a failure.\n",
    "  \n",
    "The name of this job script is the name of your job, with `.log` appended, followed by the job ID.  The command below shows you the first 20 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10f5af0a-41ec-4bed-a51b-3767f762795a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 started by s28c11n2 at 2023-08-31 16:52:23\n",
      "1 started by m28c20n2 at 2023-08-31 16:52:23\n",
      "2 started by s28c11n2 at 2023-08-31 16:52:25\n",
      "17 started by s28c11n2 at 2023-08-31 16:52:26\n",
      "7 started by s28c11n2 at 2023-08-31 16:52:26\n",
      "20 started by s28c11n2 at 2023-08-31 16:52:28\n",
      "4 started by s28c11n2 at 2023-08-31 16:52:28\n",
      "9 started by s28c11n2 at 2023-08-31 16:52:29\n",
      "19 started by s28c11n2 at 2023-08-31 16:52:29\n",
      "16 started by s28c11n2 at 2023-08-31 16:52:31\n",
      "8 started by s28c11n2 at 2023-08-31 16:52:31\n",
      "6 started by s28c11n2 at 2023-08-31 16:52:32\n",
      "18 completed by s28c11n2 at 2023-08-31 16:52:33\n",
      "1 completed by m28c20n2 at 2023-08-31 16:52:33\n",
      "11 started by s28c11n2 at 2023-08-31 16:52:35\n",
      "2 completed by s28c11n2 at 2023-08-31 16:52:36\n",
      "17 completed by s28c11n2 at 2023-08-31 16:52:36\n",
      "13 started by s28c11n2 at 2023-08-31 16:52:36\n",
      "7 completed by s28c11n2 at 2023-08-31 16:52:36\n",
      "20 completed by s28c11n2 at 2023-08-31 16:52:38\n"
     ]
    }
   ],
   "source": [
    "head -20 jobscript_parallel.slurm.log*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b905c0-1017-43e9-a527-31e361f7a8b7",
   "metadata": {},
   "source": [
    "You could of course eyeball this file to determine whether all work items completed succesfully, but atools has a command to simplify that considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457ad20a-08c7-4233-aff4-27982378f796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "  items completed: 100\n",
      "  items failed: 0\n",
      "  items to do: 0\n"
     ]
    }
   ],
   "source": [
    "arange  --data data.csv  --log jobscript_parallel.slurm.log*  --summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27a82b-ba04-4994-b754-42c18c9705d6",
   "metadata": {},
   "source": [
    "As you can see, 100 items were completed, none failed, and none left to do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
