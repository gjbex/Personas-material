{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212e39a3-b55f-43d2-a4ca-689006b4ef63",
   "metadata": {},
   "source": [
    "# HPC intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f607235-7b96-4d98-a84d-a45d5d527f76",
   "metadata": {},
   "source": [
    "## Jobs on an HPC system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36e6eb-9671-472e-8043-a676b40ff1f4",
   "metadata": {},
   "source": [
    "When you log in via the terminal to an HPC system, you typically end up on a login node, i.e., a Linux system that gives you access to the HPC infrastructure.  Although you can run data processing scripts that take little time on a login node, this infrastructure is not intended for substantial computations.  Those are performed on compute nodes of the actual compute cluster.\n",
    "\n",
    "To run an application on one or more compute nodes, you have two options:\n",
    "  * a batch job,\n",
    "  * an interactive job.\n",
    "\n",
    "The vast majority of jobs are batch jobs, i.e., they run without user intervention.  These jobs are specified as a Bash script that contains some extra information on how you want to run your job.\n",
    "\n",
    "This job script is submitted to a scheduler.  A scheduler is a software system that\n",
    "  * knows the hardware characteristics (number of cores, memory, GPUs) of each node in the cluster;\n",
    "  * the requirements of the jobs that have been submitted (requested number of nodes, cores, memory and run time)\n",
    "  * the jobs that are currently running on the cluster.\n",
    "\n",
    "Using this information, the cluster can efficiently schedule jobs on the cluster and make sure you cmoputations are executed.\n",
    "\n",
    "In this tutorial, you will learn how to write a job script, how to submit it to the scheduler, how to monitor and manage your jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a88168-0733-4e44-ba73-9cb55d18a094",
   "metadata": {},
   "source": [
    "## Job scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a3664-4b41-455b-ad86-efad8adcd9e9",
   "metadata": {},
   "source": [
    "A job script describes the work you want to do, and the resources that are required to do that.  Here you will learn about the typical anatomy of such a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45605227-2d30-4a58-96ed-c00a0837dcfb",
   "metadata": {},
   "source": [
    "### Shebang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212b95f-5d4a-495e-b45c-03b8e0d73ffc",
   "metadata": {},
   "source": [
    "  A job script is a Bash script, so like any such script, its first line is a shebang.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "```\n",
    "\n",
    "This line tells the scheduler that this is a job script that should be executing using Bash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45015c23-dae6-400c-b663-fe3e8cfdd825",
   "metadata": {},
   "source": [
    "### Scheduler directives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4622f9-4070-4169-b778-9e0380edf2f1",
   "metadata": {},
   "source": [
    "In order for the scheduler to handle your job correctly, you will have to provide some information as scheduler directives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61b45b-1cb3-4129-be01-5986be2cc8c0",
   "metadata": {},
   "source": [
    "#### Credit account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438f7fc-36e9-46fa-b96f-383740188167",
   "metadata": {},
   "source": [
    "If your HPC center uses a credit system, you have to specify a credit account you can access.  Say the name of that account is `lp_tutorial`, you would specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --account=lp_tutorial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2398718-abd9-45e8-b016-69ed0276e95b",
   "metadata": {},
   "source": [
    "You can check which credit accounts you have access to using the `sam-balance` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cafe74-67e6-4062-bf63-c8164ff54d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sam-balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15c58d-000f-40a6-8b29-04784f4e4c8e",
   "metadata": {},
   "source": [
    "If you don't see any credit accounts, you will have to apply for credits before proceding with this tutorial.  You can check how to do that in the documentation if you have a\n",
    "  * [KU Leuven affiliation](https://docs.vscentrum.be/en/latest/leuven/credits.html?highlight=credits#ku-leuven-users), or\n",
    "  * [Hasselt University affiliation](https://docs.vscentrum.be/en/latest/leuven/credits.html?highlight=credits%20uhasselt#uhasselt-users)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14f2fd-add8-49db-9b90-c04646b2eb05",
   "metadata": {},
   "source": [
    "#### Nodes and tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf40f7-79e0-4c1e-8bdd-e97f1d0cfd32",
   "metadata": {},
   "source": [
    "Next, you specify the resources you need using scheduler directives, i.e., lines that start with `#SBATCH`.  For example, you want your job to run on a single node, there is only a single task to do, and that task requires a single core.\n",
    "\n",
    "```bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213681e-929c-4648-8556-8c0078555af8",
   "metadata": {},
   "source": [
    "#### Memory requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153d18e-5d7d-46dd-907d-d8fc4767201a",
   "metadata": {},
   "source": [
    "You may also want to specify the memory usage of your application. Again, do not underestimate, but also keep in mind the hardware characteristics of the compute nodes.  If you request more memory than a node has, your job will not run.  For instance, if you are sure your job can run with 3 GB of RAM, you can specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --mem=3g\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df468d4-73ad-4e45-a3e8-68b48842d643",
   "metadata": {},
   "source": [
    "#### Walltime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132681db-94a3-4a0b-8b7d-68b810acff47",
   "metadata": {},
   "source": [
    "You would also have to specify the maximum time your script should take to run.  You have to realize that the execution of your script will be terminated once that time has elapsed, so do not underestimate it.  Time is specified as \"HHH:MM:SS\", for example, if your computation would take at most 2 hours, you would specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --time=02:00:00\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0df25e5-ba7f-4807-a577-ef88139763be",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d32668-5907-492d-9256-c4cb43b634d2",
   "metadata": {},
   "source": [
    "Up to this point, you have only specified what the scheduler should know to handle your job, but not yet what is supposed bo be computed.  Since this is a very general introduction to the job system, you will first experiment with something really simple, and after that, you can move on to domain-specific computations.\n",
    "\n",
    "You want to compute the product of pair of integers in the range 1 to 10.  In Bash, that can be done using the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a291219-a88d-47a1-872e-7652ab746648",
   "metadata": {},
   "source": [
    "```bash\n",
    "# actual computation, a bit boring\n",
    "for i in $(seq 1 10)\n",
    "do\n",
    "    for j in $(seq 1 10)\n",
    "    do\n",
    "        echo $(( $i * $j ))\n",
    "    done\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f931df-305e-4ae2-9e44-b71ae9e09f59",
   "metadata": {},
   "source": [
    "Clearly, this is not exactly an HPC-caliber computation, but again, this is just a generic example.e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580dd09-483f-4912-bbe4-2eb5a3ec32bf",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c7151-a606-4985-8538-2b5b2b564253",
   "metadata": {},
   "source": [
    "You can put all of this together in a single file `jobscript.slurm`.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH --accoun=lp_tutorial\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:05:00\n",
    "\n",
    "# don't put sleep in your job scripts, it is only added here to ensure\n",
    "# that the job will run for about 2 minutes, which gives you time to\n",
    "# monitor it with squeue after submission, see below.\n",
    "sleep 120\n",
    "\n",
    "# actual computation, a bit boring\n",
    "for i in $(seq 1 10)\n",
    "do\n",
    "    for j in $(seq 1 10)\n",
    "    do\n",
    "        echo $(( $i * $j ))\n",
    "    done\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2c1bd-ef4f-448d-a10c-d8c71785d6ec",
   "metadata": {},
   "source": [
    "Note that\n",
    "  * you have to replace `lp_tutorial` by an account you have access to;\n",
    "  * the memory has been adjusted to 1 GB;\n",
    "  * the walltime has been adjusted to 2 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab95d42-e10b-4031-b6ac-4b4dc9adb09c",
   "metadata": {},
   "source": [
    "## Job life cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415c8a2-6081-4fb1-996f-3cc29f5980df",
   "metadata": {},
   "source": [
    "The life cycle of a job consists of a number of steps that you will learn about below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c484c-931b-4811-8020-118e57cfe96f",
   "metadata": {},
   "source": [
    "### Job submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243abc27-bb1e-4591-825d-fab578d864e5",
   "metadata": {},
   "source": [
    "Your job script is now ready to be submitted to the scheduler.  You can do that using `sbatch`.  You should specify the cluster you want the job to run on, `wice` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8771e63-d872-4058-980f-95dd88c263c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbatch  --cluster=wice  jobscript.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9698b1d-90e2-4294-8a79-38d581a4c172",
   "metadata": {},
   "source": [
    "If all goes well, `sbatch` will write the job ID to standard output.  Job IDs are unique, and you can use them to monitor the status of your job, to cancel a job if necessary, or to retrieve information about it while or after it finishes.\n",
    "\n",
    "In this case, all the information required by slurm, the scheduler, is present in the job script as slurm directives (`#SBATCH`).  However, if that is not the case, or if you want different values, you can add those as command line options when you invoke `sbatch`.  For instance, to give your job a name, say \"multiplication table\", you can use the `--job-name` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f73fa1-d953-4269-9fa3-8d85da52353d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbatch  --cluster=wice  --job-name='multiplication table'  jobscript.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893dda5-417c-48e4-9d49-966c2912ad36",
   "metadata": {},
   "source": [
    "### Job status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c583c9e-4f16-46c5-9335-06f76939e040",
   "metadata": {},
   "source": [
    "Of course, you would like to keep an eye on your job(s).  You want to know whether they are still waiting to start, are running, or are completed.  The command to get this information is `squeue`.  Note that you have to specify the cluster you want to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dc653-b475-49f4-ab36-b4407e28f837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "squeue  --cluster=wice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33bc96-c877-4dc0-8d48-0de3509abd0e",
   "metadata": {},
   "source": [
    "You will get a list of jobs that are\n",
    "  * pending: these jobs are not yet running, the scheduler will start them when resources are available;\n",
    "  * running: these jobs are executing;\n",
    "  * copmleting: these jobs are about to finish.\n",
    "\n",
    "When you have submitted a job, and you don't see it anymore, it completed.\n",
    "\n",
    "The output of `squeue` contains a lot of information:\n",
    "  * `JOBID`: this is the unique ID assigned to your job;\n",
    "  * `PARTITION`: a system may have multiple partitions that you can use depending on the job characterisitcs,\n",
    "    jobs you submit using `sbatch` typically end up in the `batch` partition;\n",
    "  * `NAME`: the name you gave to your job, or the one assigned to it by slurm if you didn't specify any;\n",
    "  * `USER`: your user ID;\n",
    "  * `ST`: the state of the job, the once you see most often are\n",
    "    * `PD`: pending, i.e., waiting to be started by the scheduler;\n",
    "    * `R`: running, i.e., your job is being executed;\n",
    "    * `CG`: completing, i.e., your job is about to finish;\n",
    "  * `TIME`: the time the job has been running, so `0:00` for pending jobs;\n",
    "  * `NODES`: the number of nodes the job requires;\n",
    "  * `NODELIST(REASON)`: for running jobs, the nanme(s) of the node(s) the job is running on,\n",
    "    for pending jobs, the reason why the job is not started yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afb4b5-e01a-45c9-bb5a-c8dc83219082",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Job completion and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc33b72-5c7a-4204-bb04-02c0fb439387",
   "metadata": {},
   "source": [
    "When you no longer see your job listed in `squeue`'s output, your job has completed.  You will find a new file in the directory you submitted your job in.  The name of the file starts with `slurm-`, followed by the job ID and `.out` as extension.\n",
    "\n",
    "This file contains everyting your job script has writting to standard output and standard error.  It is a text file, so you can inspect it using your favorite editor or using a pager such as `less`.\n",
    "\n",
    "Below you see a fragment of the output file for a job like the one you just submitted.\n",
    "\n",
    "```\n",
    "SLURM_JOB_ID: 60559573\n",
    "SLURM_JOB_USER: vsc30032\n",
    "SLURM_JOB_ACCOUNT: lpt2_sysadmin\n",
    "SLURM_JOB_NAME: jobscript.slurm\n",
    "SLURM_CLUSTER_NAME: wice\n",
    "SLURM_JOB_PARTITION: batch\n",
    "SLURM_NNODES: 1\n",
    "SLURM_NODELIST: l33c32n2\n",
    "SLURM_JOB_CPUS_PER_NODE: 1\n",
    "Date: Thu Jul 27 09:44:21 CEST 2023\n",
    "Walltime: 00-00:02:00\n",
    "========================================================================\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "2\n",
    "4\n",
    "...\n",
    "```\n",
    "\n",
    "The file consists of two sections.  The first contains information about your job.  The second section, below the line of '=' characters is the actual standard output and standard error of your job, in this case our multiplication table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4dcb3-df8c-47ba-930b-52b723bbda4a",
   "metadata": {},
   "source": [
    "There are a few options to control this output:\n",
    "  * `--output=file-name`: standard output will be saved in the file with a name you provide;\n",
    "  * `--error=file-name`: standard error will be saved in the file with the name you providde.\n",
    "\n",
    "In fact, the string(s) you specify with `--output` and/or `--error` is interpreted as a file name pattern.  You can use, e.g.,\n",
    "```bash\n",
    "#SBATCH --output=multiplication_table_%j.out\n",
    "#SBATCH --error=multiplication_table_%j.err\n",
    "```\n",
    "In this pattern `%j` will be replaced by the job ID.\n",
    "\n",
    "It is considered good practice to include the job ID in the output/error file names since this makes it a lot easier to diagnose problems with a job, and link the output to other job-related information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afe144-1df8-4336-80a1-6020b7f30f7b",
   "metadata": {},
   "source": [
    "### Information on jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedbb9e8-2da0-47eb-a4a8-6d67a69ad6da",
   "metadata": {},
   "source": [
    "You may want to get some useful information on jobs, such as the walltime they used to complete, the total CPU time they consumed, or the memory they required.  This information is available through the `sacct` command (slurm accounting).  Replace the job ID in the command below by the one of the job you just ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc642af4-e56a-498d-81a1-d7417adf723e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacct --jobs 60559575"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107d8c2-1ae9-49e4-a18c-5f01d5a6e0bc",
   "metadata": {},
   "source": [
    "As you can see, by default the only useful inforamtion you get is\n",
    "  * `Account`: the credit account used for the job;\n",
    "  * ``AllocCPUS`: the number of CPUs (i.e., cores) allocated for your job;\n",
    "  * `State`: the state of your job; and\n",
    "  * `ExitCode`: this will be 0 if your job completed succesfully, non-zero otherwise.\n",
    "  \n",
    "Note that an exit code 0 doesn't necessarily mean that everything went well.  It is simply the exit code of the last Bash statement executed in your job script.  **Always check your job's output file and error file, if any.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaac5f5-aa6d-4cce-b01f-ca85174cfdc7",
   "metadata": {},
   "source": [
    "To get more details on your job, you can specify that you want particular metrics to be displayed when running `sacct`.  For instance, if you want to see the walltime (`Elapsed`), total CPU time (`CPUTime`), memory used (`MaxRSS`) your would use the `--format` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5838c9-e618-4b94-9290-c35132ebc9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacct  --jobs=60559575  --format=JobID,Elapsed,CPUTime,MaxRSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463eb1a-8224-43a9-bde4-ab91ecf34801",
   "metadata": {},
   "source": [
    "To get a list of all the information that `sacct` can provide on a job, use the `--helpformat` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821d926-dcf3-4d9c-91ad-d7c21790ecd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacct  --helpformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe53df-8254-4846-8fdc-2583473dde7d",
   "metadata": {},
   "source": [
    "**Tip:** since it is not really convenient to remember and type the `--format` option each time you use `sacct`, you can define the environment variable `SACCT_FORMAT`, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301272b-68ed-4f61-93f9-2798d124b939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export SACCT_FORMAT='JobID,Elapsed,CPUTime,MaxRSS,State'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06036769-8a16-4b1d-a89a-0adea37c5593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacct --jobs 60559573"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9aefd8-6685-44e6-b73b-59eadad7a01b",
   "metadata": {},
   "source": [
    "If you no longer want to use the format defined in `SACCT_FORMAT`, you can unset the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf472a9-093d-4672-874f-d29164a0d4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unset SACCT_FORMAT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bb77c-bdde-4f47-b48d-6a42fcd16cb6",
   "metadata": {},
   "source": [
    "### Cancelling jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a48c1-fe17-4690-9c07-dc4ec2ef237d",
   "metadata": {},
   "source": [
    "You may want to cancel a job, either while it is still pending, or when it is already running.  For instance, you may realize that you made a mistake, and that the job would not produce the results you want.  In that case, you can use the `scancel` command.\n",
    "\n",
    "First, submit a job, so that there is something to cancel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a841cb0-98f8-4391-979e-1c715350eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbatch  --cluster=wice  jobscript.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fcba9c-9191-42b9-afda-da6bcef688cf",
   "metadata": {},
   "source": [
    "Now you can cancel it, but don't forget to replace the job ID!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19861351-6857-4217-bf42-94afbf93bb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scancel 60559656 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36060260-ad59-4452-9694-968468f39f20",
   "metadata": {},
   "source": [
    "Verify the job was cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfcbda-ff2c-4832-8fdc-db21111cb883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacct --jobs 60559656"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe45133-0c47-4890-875f-17b2b21f7500",
   "metadata": {},
   "source": [
    "Obviously, you can not cancel a job that already completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a336036-51b2-416f-b45f-b7e3e296cdcc",
   "metadata": {},
   "source": [
    "## More examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f40d6b-73d4-493b-b63d-4d570a52e998",
   "metadata": {},
   "source": [
    "The job script you used in this tutorial is of course a very simple one that only executes some (pretty boring) Bash commands.  In practice, you would like for instance to run a Python or an R script, so you will find job scripts to run the scripts you wrote in those tutorials as jobs on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3918c-dbaf-43c6-a255-652036acbd60",
   "metadata": {},
   "source": [
    "### Running Python jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6349782-5ded-49c0-989b-05117e011994",
   "metadata": {},
   "source": [
    "In the [tutorial on running Python scripts](005_running_python.ipynb) you created a [script to create a plot of a sine function](005_artefacts/sin_plot.py).\n",
    "\n",
    "If you don't have the script in this directory, you can copy it from the `005_artefacts` directory.\n",
    "\n",
    "The job script to run this Python script is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3dcb9a-53f2-4594-81d9-736eb51d1a7c",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "#SBATCH --account=lp_tutorial\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:02:00\n",
    "\n",
    "# set up the environment by loading the required modules\n",
    "module purge\n",
    "module load SciPy-bundle/2021.05-foss-2021a\n",
    "module load matplotlib/3.4.2-foss-2021a\n",
    "\n",
    "# run the Python script\n",
    "python sin_plot.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e93d1c-ea2f-47b6-a39d-92f3f2af3131",
   "metadata": {},
   "source": [
    "Again, remember to replace the account by one you have access to.\n",
    "\n",
    "Note that you need to load all the required modules in your job script, in this case the Scipy-bundle and matplotlib modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bb7d5-23ea-41ed-8768-1ca5cceddabe",
   "metadata": {},
   "source": [
    "### Running R jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7da17-cf4b-482a-a878-09a9b0fd965c",
   "metadata": {},
   "source": [
    "In the [tutorial on running R scripts](007_running_R.ipynb) you created a [script to create a plot of the Airy function](07_artefacts/airy_plot.R).\n",
    "\n",
    "If you don't have the script in this directory, you can copy it from the `007_artefacts` directory.\n",
    "\n",
    "The job script to run this R script is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b29d8-abcd-4ddf-9a6f-cc4b919133d0",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "#SBATCH --account=lp_tutorial\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=1g\n",
    "#SBATCH --time=00:02:00\n",
    "\n",
    "# set up the environment by loading the required modules\n",
    "module purge\n",
    "module load R/4.1.0-foss-2021a\n",
    "module load GSL/2.7-GCC-10.3.0\n",
    "\n",
    "# run the R script\n",
    "Rscript airy_plot.R\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b5ee3-c79d-4da4-b327-bd8f736b9462",
   "metadata": {},
   "source": [
    "Again, remember to replace the account by one you have access to.\n",
    "\n",
    "Note that in addition to the R module, you also have to load the GSL module since the R library you use in this script requires it at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193fdf0e-150c-45bb-90cf-1cc531ac03a5",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc611ed-a3af-4998-8a4b-7a7000e5d3ce",
   "metadata": {},
   "source": [
    "In this tutorial, you learned about the basics of job scripts and the scheduler, now you know how to use the cluster in its normal mode of operation, i.e., batch mode, submitting jobs to the scheduler.\n",
    "\n",
    "You learned\n",
    "  * how to write a job script by\n",
    "    * specifying directives for the scheduler,\n",
    "    * specifying the commands you want to be executed in your job;\n",
    "  * to submit a job to the scheduler using `sbatch`;\n",
    "  * to monitor the state of your job using `squeue`;\n",
    "  * to get information on your job using `sacct`;\n",
    "  * to cancel a job using `scancel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410d5e8-4e7f-415f-ae55-8a5fa49fb185",
   "metadata": {},
   "source": [
    "## Where to go from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b874e0-d411-414c-8a23-0b7a63a71ad4",
   "metadata": {},
   "source": [
    "There is of course much more to learn about running jobs on an HPC system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
