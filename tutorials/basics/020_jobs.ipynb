{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212e39a3-b55f-43d2-a4ca-689006b4ef63",
   "metadata": {},
   "source": [
    "# HPC intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f607235-7b96-4d98-a84d-a45d5d527f76",
   "metadata": {},
   "source": [
    "## Jobs on an HPC system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36e6eb-9671-472e-8043-a676b40ff1f4",
   "metadata": {},
   "source": [
    "When you log in via the terminal to an HPC system, you typically end up on a login node, i.e., a Linux system that gives you access to the HPC infrastructure.  Although you can run data processing scripts that take little time on a login node, this infrastructure is not intended for substantial computations.  Those are performed on compute nodes of the actual compute cluster.\n",
    "\n",
    "To run an application on one or more compute nodes, you have two options:\n",
    "  * a batch job,\n",
    "  * an interactive job.\n",
    "\n",
    "The vast majority of jobs are batch jobs, i.e., they run without user intervention.  These jobs are specified as a Bash script that contains some extra information on how you want to run your job.\n",
    "\n",
    "This job script is submitted to a scheduler.  A scheduler is a software system that\n",
    "  * knows the hardware characteristics (number of cores, memory, GPUs) of each node in the cluster;\n",
    "  * the requirements of the jobs that have been submitted (requested number of nodes, cores, memory and run time)\n",
    "  * the jobs that are currently running on the cluster.\n",
    "\n",
    "Using this information, the cluster can efficiently schedule jobs on the cluster and make sure you cmoputations are executed.\n",
    "\n",
    "In this tutorial, you will learn how to write a job script, how to submit it to the scheduler, how to monitor and manage your jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a88168-0733-4e44-ba73-9cb55d18a094",
   "metadata": {},
   "source": [
    "## Job scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a3664-4b41-455b-ad86-efad8adcd9e9",
   "metadata": {},
   "source": [
    "A job script describes the work you want to do, and the resources that are required to do that.  Here you will learn about the typical anatomy of such a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45605227-2d30-4a58-96ed-c00a0837dcfb",
   "metadata": {},
   "source": [
    "### Shebang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212b95f-5d4a-495e-b45c-03b8e0d73ffc",
   "metadata": {},
   "source": [
    "  A job script is a Bash script, so like any such script, its first line is a shebang.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "```\n",
    "\n",
    "This line tells the scheduler that this is a job script that should be executing using Bash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45015c23-dae6-400c-b663-fe3e8cfdd825",
   "metadata": {},
   "source": [
    "### Scheduler directives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4622f9-4070-4169-b778-9e0380edf2f1",
   "metadata": {},
   "source": [
    "In order for the scheduler to handle your job correctly, you will have to provide some information as scheduler directives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61b45b-1cb3-4129-be01-5986be2cc8c0",
   "metadata": {},
   "source": [
    "#### Credit account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438f7fc-36e9-46fa-b96f-383740188167",
   "metadata": {},
   "source": [
    "If your HPC center uses a credit system, you have to specify a credit account you can access.  Say the name of that account is `lp_multiscale_physics`, you would specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --account=lp_multiscale_physics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14f2fd-add8-49db-9b90-c04646b2eb05",
   "metadata": {},
   "source": [
    "#### Nodes and tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf40f7-79e0-4c1e-8bdd-e97f1d0cfd32",
   "metadata": {},
   "source": [
    "Next, you specify the resources you need using scheduler directives, i.e., lines that start with `#SBATCH`.  For example, you want your job to run on a single node, there is only a single task to do, and that task requires a single core.\n",
    "\n",
    "```bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4213681e-929c-4648-8556-8c0078555af8",
   "metadata": {},
   "source": [
    "#### Memory requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153d18e-5d7d-46dd-907d-d8fc4767201a",
   "metadata": {},
   "source": [
    "You may also want to specify the memory usage of your application. Again, do not underestimate, but also keep in mind the hardware characteristics of the compute nodes.  If you request more memory than a node has, your job will not run.  For instance, if you are sure your job can run with 3 GB of RAM, you can specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --mem=3g\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df468d4-73ad-4e45-a3e8-68b48842d643",
   "metadata": {},
   "source": [
    "#### Walltime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132681db-94a3-4a0b-8b7d-68b810acff47",
   "metadata": {},
   "source": [
    "You would also have to specify the maximum time your script should take to run.  You have to realize that the execution of your script will be terminated once that time has elapsed, so do not underestimate it.  Time is specified as \"HHH:MM:SS\", for example, if your computation would take at most 2 hours, you would specify that as follows.\n",
    "\n",
    "```bash\n",
    "#SBATCH --time=02:00:00\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0df25e5-ba7f-4807-a577-ef88139763be",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d32668-5907-492d-9256-c4cb43b634d2",
   "metadata": {},
   "source": [
    "Up to this point, you have only specified what the scheduler should know to handle your job, but not yet what is supposed bo be computed.  Since this is a very general introduction to the job system, you will first experiment with something really simple, and after that, you can move on to domain-specific computations.\n",
    "\n",
    "You want to compute the product of pair of integers in the range 1 to 10.  In Bash, that can be done using the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a291219-a88d-47a1-872e-7652ab746648",
   "metadata": {},
   "source": [
    "```bash\n",
    "for i in $(seq 1 10)\r",
    "do    \r",
    "    for j in $(seq 1 10)\r\n",
    "     o         e o $(chi$$*$j $\n",
    "    don  neo```\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f931df-305e-4ae2-9e44-b71ae9e09f59",
   "metadata": {},
   "source": [
    "Clearly, this is not exactly an HPC-caliber computation, but again, this is just a generic example.e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580dd09-483f-4912-bbe4-2eb5a3ec32bf",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c7151-a606-4985-8538-2b5b2b564253",
   "metadata": {},
   "source": [
    "You can put all of this together in a single file `jobscript.slurm`.\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env bash\r\n",
    "#SBATCH --accoun= lp_multiscale_physics\r\n",
    "#SBATCH --nodes=1\r\n",
    "#SBATCH --ntasks=1\r\n",
    "#SBATCH --cpus-per-task=1\r\n",
    "#SBATCH --mem=1g\r\n",
    "#SBATCH --time=00:02:--\r\n",
    "\r\n",
    "for i in $(seq 1 10)\r\n",
    "do\r\n",
    "    for j in $(seq 1 10)\r\n",
    "    do\r\n",
    "        echo $(( $i * $j ))\r\n",
    "    done\r\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2c1bd-ef4f-448d-a10c-d8c71785d6ec",
   "metadata": {},
   "source": [
    "Note that\n",
    "  * you have to replace `lp_multiscale_physics` by an account you have access to;\n",
    "  * the memory has been adjusted to 1 GB;\n",
    "  * the walltime has been adjusted to 2 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c484c-931b-4811-8020-118e57cfe96f",
   "metadata": {},
   "source": [
    "## Job submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243abc27-bb1e-4591-825d-fab578d864e5",
   "metadata": {},
   "source": [
    "Your job script is now ready to be submitted to the scheduler.  You can do that using `sbatch`.  You should specify the cluster you want the job to run on, `wice` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8771e63-d872-4058-980f-95dd88c263c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch  --cluster=wice  jobscript.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9698b1d-90e2-4294-8a79-38d581a4c172",
   "metadata": {},
   "source": [
    "If all goes well, `sbatch` will write the job ID to standard output.  Job IDs are unique, and you can use them to monitor the status of your job, to cancel a job if necessary, or to retrieve information about it while or after it finishes.\n",
    "\n",
    "In this case, all the information required by slurm, the scheduler, is present in the job script as slurm directives (`#SBATCH`).  However, if that is not the case, or if you want different values, you can add those as command line options when you invoke `sbatch`.  For instance, to give your job a name, say \"helle from R\", you can use the `--job-name` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f73fa1-d953-4269-9fa3-8d85da52353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch  --cluster=wice  --job-name 'hello from R'  jobscript.slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893dda5-417c-48e4-9d49-966c2912ad36",
   "metadata": {},
   "source": [
    "## Job status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c583c9e-4f16-46c5-9335-06f76939e040",
   "metadata": {},
   "source": [
    "Of course, you would like to keep an eye on your job(s).  You want to know whether they are still waiting to start, are running, or are completed.  The command to get this information is `squeue`.  Note that you have to specify the cluster you want to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6dc653-b475-49f4-ab36-b4407e28f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeue  --cluster=wice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33bc96-c877-4dc0-8d48-0de3509abd0e",
   "metadata": {},
   "source": [
    "You will get a list of jobs that are\n",
    "  * queued (status `Q`): these jobs are not yet running, the scheduler will start them when resources are available;\n",
    "  * running (status `R`): these jobs are executing.\n",
    "\n",
    "When you have submitted a job, and you don't see it anymore, it completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193fdf0e-150c-45bb-90cf-1cc531ac03a5",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410d5e8-4e7f-415f-ae55-8a5fa49fb185",
   "metadata": {},
   "source": [
    "## Where to go from here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
